{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712bfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dc32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ['DATA_DIR_VG_RCNN'] = '/users/zhanwenchen/datasets'\n",
    "# from maskrcnn_benchmark.data.graft_augmenter import GraftAugmenterDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8249aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set args\n",
    "# PRETRAINED\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "\n",
    "MODEL_NAME = '44663493_vctree_baseline_predcls_4GPU_riv_1_copied'\n",
    "CONFIG_FILE = '/users/zhanwenchen/gsc/checkpoints/44663493_vctree_baseline_predcls_4GPU_riv_1_copied/config.yml'\n",
    "PROJECT_DIR = '/users/zhanwenchen/gsc'\n",
    "SEED=1234\n",
    "BATCH_SIZE=1\n",
    "\n",
    "cfg.merge_from_file(CONFIG_FILE)\n",
    "cfg.SOLVER.IMS_PER_BATCH = BATCH_SIZE\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "cfg.GLOVE_DIR = f'{PROJECT_DIR}/datasets/vg/'\n",
    "cfg.MODEL.PRETRAINED_DETECTOR_CKPT = f'{PROJECT_DIR}/checkpoints/pretrained_faster_rcnn/model_final.pth'\n",
    "cfg.OUTPUT_DIR = f'{PROJECT_DIR}/checkpoints/{MODEL_NAME}'\n",
    "cfg.PATHS_DATA = f'{PROJECT_DIR}/maskrcnn_benchmark/data/datasets'\n",
    "cfg.OUTPUT_DIR = '/users/zhanwenchen/gsc/checkpoints/44663493_vctree_baseline_predcls_4GPU_riv_1_copied'\n",
    "cfg.MODEL.WEIGHT = f'{PROJECT_DIR}/checkpoints/{MODEL_NAME}/model_0014000.pth'\n",
    "cfg.PATHS_CATALOG = '/users/zhanwenchen/gsc/maskrcnn_benchmark/config/paths_catalog.py'\n",
    "\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03412d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graft_augmenter_dataset = GraftAugmenterDataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3963bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data.sampler import RandomSampler, SequentialSampler, BatchSampler\n",
    "# from maskrcnn_benchmark.utils.comm import get_world_size\n",
    "# from maskrcnn_benchmark.data.build import make_batch_data_sampler, make_data_sampler\n",
    "# from maskrcnn_benchmark.data import samplers\n",
    "# # from maskrcnn_benchmark.data.build import make_batch_data_sampler, make_data_sampler, _compute_aspect_ratios, _quantize\n",
    "# from maskrcnn_benchmark.data.transforms import build_transforms\n",
    "# from maskrcnn_benchmark.data.samplers import DistributedSampler\n",
    "# from maskrcnn_benchmark.data.collate_batch import BatchCollator, BBoxAugCollator\n",
    "\n",
    "\n",
    "# # def make_batch_data_sampler(\n",
    "# #     dataset, sampler, aspect_grouping, images_per_batch, num_iters=None, start_iter=0\n",
    "# # ):\n",
    "# #     if aspect_grouping:\n",
    "# #         if not isinstance(aspect_grouping, (list, tuple)):\n",
    "# #             aspect_grouping = [aspect_grouping]\n",
    "# #         aspect_ratios = _compute_aspect_ratios(dataset.dataset)\n",
    "# #         group_ids = _quantize(aspect_ratios, aspect_grouping)\n",
    "# #         batch_sampler = samplers.GroupedBatchSampler(\n",
    "# #             sampler, group_ids, images_per_batch, drop_uneven=False\n",
    "# #         )\n",
    "# #     else:\n",
    "# #         batch_sampler = BatchSampler(\n",
    "# #             sampler, images_per_batch, drop_last=False\n",
    "# #         )\n",
    "# #     if num_iters is not None:\n",
    "# #         batch_sampler = samplers.IterationBasedBatchSampler(\n",
    "# #             batch_sampler, num_iters, start_iter\n",
    "# #         )\n",
    "# #     return batch_sampler\n",
    "\n",
    "\n",
    "# def make_data_loader_graft(cfg, mode='train', is_distributed=False, start_iter=0):\n",
    "#     assert mode in {'train', 'val', 'test'}\n",
    "#     logger = logging.getLogger(__name__)\n",
    "#     num_gpus = get_world_size()\n",
    "#     is_train = mode == 'train'\n",
    "#     if is_train:\n",
    "#         images_per_batch = cfg.SOLVER.IMS_PER_BATCH\n",
    "#         assert (\n",
    "#             images_per_batch % num_gpus == 0\n",
    "#         ), \"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\".format(\n",
    "#             images_per_batch, num_gpus)\n",
    "#         images_per_gpu = images_per_batch // num_gpus\n",
    "#         logger.warning(\n",
    "#             \"Images Per GPU: \"+str(images_per_gpu)\n",
    "#             )\n",
    "#         shuffle = True\n",
    "#         num_iters = cfg.SOLVER.MAX_ITER\n",
    "#     else:\n",
    "#         images_per_batch = cfg.TEST.IMS_PER_BATCH\n",
    "#         assert (\n",
    "#             images_per_batch % num_gpus == 0\n",
    "#         ), \"TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\".format(\n",
    "#             images_per_batch, num_gpus)\n",
    "#         images_per_gpu = images_per_batch // num_gpus\n",
    "#         shuffle = False\n",
    "#         print(f'is_distributed={is_distributed}, shuffle={shuffle}')\n",
    "#         num_iters = None\n",
    "#         start_iter = 0\n",
    "\n",
    "#     if images_per_gpu > 1:\n",
    "#         logger.warning(\n",
    "#             \"When using more than one image per GPU you may encounter \"\n",
    "#             \"an out-of-memory (OOM) error if your GPU does not have \"\n",
    "#             \"sufficient memory. If this happens, you can reduce \"\n",
    "#             \"SOLVER.IMS_PER_BATCH (for training) or \"\n",
    "#             \"TEST.IMS_PER_BATCH (for inference). For training, you must \"\n",
    "#             \"also adjust the learning rate and schedule length according \"\n",
    "#             \"to the linear scaling rule. See for example: \"\n",
    "#             \"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\"\n",
    "#         )\n",
    "\n",
    "#     # group images which have similar aspect ratio. In this case, we only\n",
    "#     # group in two cases: those with width / height > 1, and the other way around,\n",
    "#     # but the code supports more general grouping strategy\n",
    "#     aspect_grouping = [1] if cfg.DATALOADER.ASPECT_RATIO_GROUPING else []\n",
    "\n",
    "#     dataset_list = cfg.DATASETS.TRAIN\n",
    "    \n",
    "#     dataset_aug = GraftAugmenterDataset(cfg)\n",
    "#     dataset_train_combined = ([dataset.dataset, dataset])\n",
    "# #     dataloader_train = DataLoader(dataset=train_dev_sets, ...)\n",
    "\n",
    "#     # If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later\n",
    "#     transforms = None if not is_train and cfg.TEST.BBOX_AUG.ENABLED else build_transforms(cfg, is_train)\n",
    "#     sampler = make_data_sampler(dataset, shuffle, is_distributed)\n",
    "#     batch_sampler = make_batch_data_sampler(\n",
    "#         dataset, sampler, aspect_grouping, images_per_gpu, num_iters, start_iter\n",
    "#     )\n",
    "#     collator = BBoxAugCollator() if not is_train and cfg.TEST.BBOX_AUG.ENABLED else \\\n",
    "#         BatchCollator(cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "#     data_loader = DataLoader(\n",
    "#         dataset,\n",
    "#         num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
    "#         batch_sampler=batch_sampler,\n",
    "#         collate_fn=collator,\n",
    "#         pin_memory=True,\n",
    "#     )\n",
    "\n",
    "#     return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7418be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_graft = make_data_loader_graft(cfg, mode='train', is_distributed=False, start_iter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d764aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataloader_graft.dataset.dataset) # 57723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207e1cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(dataloader_graft.dataset) # 14520 # total: 72243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67225882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for iteration, (images, targets, _) in enumerate(dataloader_graft):\n",
    "#     print(f'i={iteration}')\n",
    "#     import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138dbcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.SOLVER.AUGMENTATION.USE_GRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b097948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images Per GPU: 1\n",
      "Images Per GPU: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:  train\n",
      "root_classes_count:  {}\n",
      "mean root class number:  0.0\n",
      "sum root class number:  0\n",
      "leaf_classes_count:  {}\n",
      "mean leaf class number:  0.0\n",
      "sum leaf class number:  0\n",
      "all_classes_count:  {}\n",
      "mean all class number:  0.0\n",
      "sum all class number:  0\n",
      "number images:  57723\n",
      "split:  train\n",
      "root_classes_count:  {}\n",
      "mean root class number:  0.0\n",
      "sum root class number:  0\n",
      "leaf_classes_count:  {}\n",
      "mean leaf class number:  0.0\n",
      "sum leaf class number:  0\n",
      "all_classes_count:  {}\n",
      "mean all class number:  0.0\n",
      "sum all class number:  0\n",
      "number images:  57723\n",
      "GraftAugmenterDataset.__init__: started running get_dataset_statistics\n",
      "dataset_name=VG_stanford_filtered_with_attribute_train\n",
      "split:  train\n",
      "root_classes_count:  {}\n",
      "mean root class number:  0.0\n",
      "sum root class number:  0\n",
      "leaf_classes_count:  {}\n",
      "mean leaf class number:  0.0\n",
      "sum leaf class number:  0\n",
      "all_classes_count:  {}\n",
      "mean all class number:  0.0\n",
      "sum all class number:  0\n",
      "number images:  57723\n",
      "get visual genome statistics!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 57723/57723 [00:09<00:00, 5846.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraftAugmenterDataset.__init__: finished running get_dataset_statistics\n",
      "GraftAugmenterDataset.__init__: started converting stats to df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset [ConcatDataset] has no categories attribute, labels.json file won't be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraftAugmenterDataset.__init__: finished converting stats to df\n",
      "GraftAugmenterDataset.__init__: started converting stats to df\n",
      "GraftAugmenterDataset.__init__: started querying for least frequent relations\n",
      "GraftAugmenterDataset.__init__: finished querying for least frequent relations\n"
     ]
    }
   ],
   "source": [
    "from maskrcnn_benchmark.data import make_data_loader, get_dataset_statistics\n",
    "\n",
    "\n",
    "train_data_loader = make_data_loader(\n",
    "        cfg,\n",
    "        mode='train',\n",
    "        is_distributed=False,\n",
    "        start_iter=0,\n",
    "        aug=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f5643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72243"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration, (images, targets, _) in enumerate(train_data_loader):\n",
    "    print(f'i={iteration}')\n",
    "    import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image tensors vs targets mismatch. Does that also happen with the original dataloader? Yes.\n",
    "# images.tensors.size() # torch.Size([1, 3, 928, 608])\n",
    "# targets[0].size # (600, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dataset_train_combined = ([train_set, dev_set])\n",
    "dataloader_train = DataLoader(dataset=train_dev_sets, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loader(cfg, mode='train', is_distributed=False, start_iter=0):\n",
    "    assert mode in {'train', 'val', 'test'}\n",
    "    logger = logging.getLogger(__name__)\n",
    "    num_gpus = get_world_size()\n",
    "    is_train = mode == 'train'\n",
    "    if is_train:\n",
    "        images_per_batch = cfg.SOLVER.IMS_PER_BATCH\n",
    "        assert (\n",
    "            images_per_batch % num_gpus == 0\n",
    "        ), \"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\".format(\n",
    "            images_per_batch, num_gpus)\n",
    "        images_per_gpu = images_per_batch // num_gpus\n",
    "        logger.warning(\n",
    "            \"Images Per GPU: \"+str(images_per_gpu)\n",
    "            )\n",
    "        shuffle = True\n",
    "        num_iters = cfg.SOLVER.MAX_ITER\n",
    "    else:\n",
    "        images_per_batch = cfg.TEST.IMS_PER_BATCH\n",
    "        assert (\n",
    "            images_per_batch % num_gpus == 0\n",
    "        ), \"TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\".format(\n",
    "            images_per_batch, num_gpus)\n",
    "        images_per_gpu = images_per_batch // num_gpus\n",
    "        shuffle = False\n",
    "        print(f'is_distributed={is_distributed}, shuffle={shuffle}')\n",
    "        num_iters = None\n",
    "        start_iter = 0\n",
    "\n",
    "    if images_per_gpu > 1:\n",
    "        logger.warning(\n",
    "            \"When using more than one image per GPU you may encounter \"\n",
    "            \"an out-of-memory (OOM) error if your GPU does not have \"\n",
    "            \"sufficient memory. If this happens, you can reduce \"\n",
    "            \"SOLVER.IMS_PER_BATCH (for training) or \"\n",
    "            \"TEST.IMS_PER_BATCH (for inference). For training, you must \"\n",
    "            \"also adjust the learning rate and schedule length according \"\n",
    "            \"to the linear scaling rule. See for example: \"\n",
    "            \"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\"\n",
    "        )\n",
    "\n",
    "    # group images which have similar aspect ratio. In this case, we only\n",
    "    # group in two cases: those with width / height > 1, and the other way around,\n",
    "    # but the code supports more general grouping strategy\n",
    "    aspect_grouping = [1] if cfg.DATALOADER.ASPECT_RATIO_GROUPING else []\n",
    "\n",
    "    paths_catalog = import_file(\n",
    "        \"maskrcnn_benchmark.config.paths_catalog\", cfg.PATHS_CATALOG, True\n",
    "    )\n",
    "    DatasetCatalog = paths_catalog.DatasetCatalog\n",
    "    if mode == 'train':\n",
    "        dataset_list = cfg.DATASETS.TRAIN\n",
    "    elif mode == 'val':\n",
    "        dataset_list = cfg.DATASETS.VAL\n",
    "    else:\n",
    "        dataset_list = cfg.DATASETS.TEST\n",
    "\n",
    "    # If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later\n",
    "    transforms = None if not is_train and cfg.TEST.BBOX_AUG.ENABLED else build_transforms(cfg, is_train)\n",
    "    datasets = build_dataset(cfg, dataset_list, transforms, DatasetCatalog, is_train)\n",
    "\n",
    "    if is_train:\n",
    "        # save category_id to label name mapping\n",
    "        save_labels(datasets, cfg.OUTPUT_DIR)\n",
    "\n",
    "    data_loaders = []\n",
    "    for dataset in datasets:\n",
    "        # print('============')\n",
    "        # print(len(dataset))\n",
    "        # print(images_per_gpu)\n",
    "        # print('============')\n",
    "        sampler = make_data_sampler(dataset, shuffle, is_distributed)\n",
    "        batch_sampler = make_batch_data_sampler(\n",
    "            dataset, sampler, aspect_grouping, images_per_gpu, num_iters, start_iter\n",
    "        )\n",
    "        collator = BBoxAugCollator() if not is_train and cfg.TEST.BBOX_AUG.ENABLED else \\\n",
    "            BatchCollator(cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "        num_workers = cfg.DATALOADER.NUM_WORKERS\n",
    "        data_loader = DataLoader(\n",
    "            dataset,\n",
    "            num_workers=num_workers,\n",
    "            batch_sampler=batch_sampler,\n",
    "            collate_fn=collator,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        data_loaders.append(data_loader)\n",
    "    if is_train:\n",
    "        # during training, a single (possibly concatenated) data_loader is returned\n",
    "        assert len(data_loaders) == 1\n",
    "        return data_loaders[0]\n",
    "    return data_loaders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
